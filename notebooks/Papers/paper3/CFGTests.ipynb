{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natalie', 'Wood', \"'s\", 'sister', 'claims', 'to', 'know', 'actress', \"'\", 'killer']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Natalie Wood's sister claims to know actress' killer\n",
    "\"\"\"\n",
    "\n",
    "words = word_tokenize(text)\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Natalie', 'NNP'), ('Wood', 'NNP'), (\"'s\", 'POS'), ('sister', 'NN'), ('claims', 'VBZ'), ('to', 'TO'), ('know', 'VB'), ('actress', 'NN'), (\"'\", \"''\"), ('killer', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "taggedWords = pos_tag(words)\n",
    "\n",
    "print(taggedWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natalie Wood's sister claims to know actress' killer\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    " S -> NNP VBZ TO VB NN\n",
    " TO -> \"to\"\n",
    " NNP -> \"Natalie Wood's sister\"\n",
    " VP -> V NP | V NP PP\n",
    " VBZ -> \"claims\"\n",
    " VB -> \"know\"\n",
    " NN -> \"actress' killer\"\n",
    " \"\"\")\n",
    "\n",
    "for sentence in generate(grammar, n=10):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNew York boy, 5, tests negative for Ebola\\n\\nNoah: 'Russell Crowe is just about the only actor who could have pulled this off'\\n    \\nTurkey’s Erdogan Condemns EU, Pope Francis Over Armenian ‘Genocide’ Label\\n\\nNatalie Wood's sister claims to know actress' killer\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "New York boy, 5, tests negative for Ebola\n",
    "\n",
    "Noah: 'Russell Crowe is just about the only actor who could have pulled this off'\n",
    "    \n",
    "Turkey’s Erdogan Condemns EU, Pope Francis Over Armenian ‘Genocide’ Label\n",
    "\n",
    "Natalie Wood's sister claims to know actress' killer\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package path: /notebooks/packages\n",
      "Data path: /notebooks/data\n",
      "Output path: /notebooks/output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import os, sys\n",
    "dirPath = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "packagesPath = os.path.abspath(os.path.join(dirPath, '../../', 'packages'))\n",
    "print(\"Package path:\", packagesPath)\n",
    "dataPath = os.path.abspath(os.path.join(dirPath, '../../', 'data'))\n",
    "print(\"Data path:\", dataPath)\n",
    "outputPath = os.path.abspath(os.path.join(dirPath, '../../', 'output'))\n",
    "print(\"Output path:\", outputPath)\n",
    "\n",
    "if not packagesPath in sys.path:\n",
    "    sys.path.append(packagesPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_generator.title as title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# train = True\n",
    "# #datasetPath =  os.path.abspath(os.path.join(dataPath, \"Data-Obama/*.*\"))\n",
    "# datasetPath =  os.path.abspath(os.path.join(dataPath, \"Titles/title.txt\"))\n",
    "\n",
    "# print(datasetPath)\n",
    "# keyLen = 1\n",
    "# fileList = []\n",
    "# #dictionaryFilePath = os.path.abspath(os.path.join(outputPath, \"data_obama.txt\"))\n",
    "# dictionaryFilePath = os.path.abspath(os.path.join(outputPath, \"titlePos.txt\"))\n",
    "# print(dictionaryFilePath)\n",
    "# if train :\n",
    "#     fileList += glob.glob(datasetPath)\n",
    "#     print(\"Input files\")\n",
    "#     print(fileList)\n",
    "#     markovObj = title.Title(order=2)\n",
    "\n",
    "\n",
    "#     for file in fileList:\n",
    "#         print(file)\n",
    "#         try:\n",
    "#             markovObj.readFile(file, \"utf-8\")\n",
    "#         except:\n",
    "#             markovObj.readFile(file, \"windows-1252\")\n",
    "\n",
    "#     markovObj.outputDict(dictionaryFilePath)\n",
    "\n",
    "#     print( \"Generated Markov dictionary %s \" % ( dictionaryFilePath) ) \n",
    "    \n",
    "#     rules = markovObj.genGrammer()\n",
    "#     print(rules)\n",
    "#     grammar = nltk.CFG.fromstring(rules)\n",
    "\n",
    "#     for sentence in generate(grammar, n=2):\n",
    "#         print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/data/Titles/title.txt\n",
      "['NNP', 'NNP', 'IN', 'NN', 'PRP', 'DT', 'NN', 'NN', '.', 'END']\n",
      "['NNP', 'VBZ', 'JJ', 'NN', 'NN', 'NN', 'IN', 'DT', 'NN', 'NN', '.', 'END']\n",
      "['NNP', 'IN', 'NNP', 'NNS', 'VBG', 'NN', 'RB', ':', 'NN', '.', 'END']\n",
      "['MD', 'NN', 'VB', 'DT', 'JJ', 'NN', 'NN', '.', 'END']\n",
      "['WRB', 'JJ', 'VBZ', 'DT', 'JJ', 'NN', 'IN', 'DT', 'NN', '.', 'END']\n",
      "['NN', 'NN', 'VBZ', 'IN', 'NN', 'NNS', 'JJ', 'NN', '.', 'END']\n",
      "['NNP', 'NNP', 'NNP', 'MD', 'VB', 'VB', 'IN', 'NN', 'IN', 'NN', '.', 'END']\n",
      "['NNP', 'VBP', 'NN', 'TO', 'VB', 'NN', 'NN', '.', 'END']\n",
      "['DT', 'JJ', 'NN', 'IN', 'CD', 'IN', 'CD', '.', 'END']\n",
      "['JJ', 'NN', ':', 'JJ', 'NNS', 'IN', 'DT', 'NNS', 'JJS', 'NN', '.', 'END']\n",
      "['NNP', 'VBZ', 'NN', 'IN', 'NNP', 'NNP', 'NN', '.', 'END']\n",
      "['JJ', 'NNP', 'NN', 'IN', 'NNP', 'NNS', '.', 'END']\n",
      "['NNP', 'TO', 'VB', 'NNP', 'NN', 'TO', 'VB', 'NNP', 'NN', '.', 'END']\n",
      "['NNP', 'NNP', 'NNP', 'NN', 'IN', 'DT', 'NN', '.', 'END']\n",
      "['NN', 'IN', 'RBR', 'JJ', 'NNP', 'NN', 'NN', '.', 'END']\n",
      "['IN', 'PRP', 'VBG', 'IN', 'IN', 'JJ', 'NN', '.', 'END']\n",
      "------\n",
      "['START', 'NNP', 'IN', 'NN', 'PRP', 'DT', '.', 'END', 'VBZ', 'JJ', 'NNS', 'VBG', 'RB', ':', 'MD', 'VB', 'WRB', 'VBP', 'TO', 'CD', 'JJS', 'RBR']\n",
      "[0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "[0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "[0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{'START': {'NNP': 8, 'MD': 1, 'WRB': 1, 'NN': 2, 'DT': 1, 'JJ': 2, 'IN': 1}, 'NNP': {'NNP': 6, 'IN': 2, 'VBZ': 2, 'NNS': 2, 'MD': 1, 'VBP': 1, 'NN': 6, 'TO': 1}, 'IN': {'NN': 4, 'DT': 4, 'NNP': 3, 'CD': 2, 'RBR': 1, 'PRP': 1, 'IN': 1, 'JJ': 1}, 'NN': {'PRP': 1, 'NN': 8, '.': 14, 'IN': 8, 'RB': 1, 'VB': 1, 'VBZ': 1, 'NNS': 1, 'TO': 2, ':': 1}, 'PRP': {'DT': 1, 'VBG': 1}, 'DT': {'NN': 4, 'JJ': 3, 'NNS': 1}, '.': {'END': 16}, 'END': {}, 'VBZ': {'JJ': 1, 'DT': 1, 'IN': 1, 'NN': 1}, 'JJ': {'NN': 7, 'VBZ': 1, 'NNS': 1, 'NNP': 2}, 'NNS': {'VBG': 1, 'JJ': 1, 'IN': 1, 'JJS': 1, '.': 1}, 'VBG': {'NN': 1, 'IN': 1}, 'RB': {':': 1}, ':': {'NN': 1, 'JJ': 1}, 'MD': {'NN': 1, 'VB': 1}, 'VB': {'DT': 1, 'VB': 1, 'IN': 1, 'NN': 1, 'NNP': 2}, 'WRB': {'JJ': 1}, 'VBP': {'NN': 1}, 'TO': {'VB': 3}, 'CD': {'IN': 1, '.': 1}, 'JJS': {'NN': 1}, 'RBR': {'JJ': 1}}\n",
      "{'NNP': ['Labour', 'MPs', 'UK', 'Third', 'Sir', 'Graham', 'Brady', 'Toyota', 'PMs', 'Brexit', 'Sony', 'Europe', 'Could', 'Channel', 'Ports', 'EU'], 'IN': ['in', 'for', 'of', 'as', 'if', 'against', 'about', 'with', 'Are', 'out'], 'NN': ['show', 'money', 'row', 'product', 'safety', 'mark', 'deal', 'scenario', 'move', 'survey', 'technology', 'border', 'problem', 'government', 'Car', 'investment', 'industry', 'alert', 'place', 'departure', 'date', 'match', 'trade', 'support', 'warning', 'headquarters', 'disruption', 'cope', 'Push', 'no-deal', 'offer', 'time'], 'PRP': ['us', 'we'], 'DT': ['the', 'no', 'A'], '.': ['.', '?'], 'VBZ': ['plans', 'is', 'halves', 'urges'], 'JJ': ['new', 'Irish', 'ready', 'UK', 'red', 'staring', 'EU-Japan', 'Five', 'No-deal', 'generous', 'parliamentary'], 'NNS': ['businesses', 'hits', 'things', 'worlds', 'drivers'], 'VBG': ['considering', 'running'], 'RB': ['abroad'], ':': ['-', ':'], 'MD': ['Can', 'could'], 'VB': ['solve', 'accept', 'delay', 'move', 'avoid'], 'WRB': ['How'], 'VBP': ['reject'], 'TO': ['to'], 'CD': ['one', '27'], 'JJS': ['biggest'], 'RBR': ['more']}\n",
      "Max length:  11\n",
      " START NN PRP VBG IN RBR JJ NNS IN PRP DT NN VB VB DT NNS JJ NNS IN NN VB VB NN TO VB IN PRP VBG NN : JJ NN RB : JJ VBZ IN IN DT NNS IN RBR JJ NNP NN VB IN RBR JJ VBZ NN .\n",
      " START JJ NN IN IN CD IN RBR JJ NN IN CD IN DT NN VB NNP VBP NN NNS JJS NN : NN IN IN DT NNS VBG NN NN VB VB DT NN PRP DT JJ NNS VBG IN CD IN NNP NN NN RB : NN NN NN NNS IN JJ NNS IN JJ NNP VBP NN .\n",
      " START DT NN NN NNS JJ NN VBZ DT JJ NNP VBP NN : NN .\n"
     ]
    }
   ],
   "source": [
    "import text_generator.rules as rules\n",
    "import glob\n",
    "datasetPath =  os.path.abspath(os.path.join(dataPath, \"Titles/title.txt\"))\n",
    "\n",
    "fileList = []\n",
    "fileList += glob.glob(datasetPath)\n",
    "\n",
    "rulesGenerator = rules.Rules()\n",
    "\n",
    "for file in fileList:\n",
    "    print(file)\n",
    "    rulesGenerator.processFile(file, \"utf-8\")\n",
    "    print(rulesGenerator.getRuleText())\n",
    "    print(rulesGenerator.getRuleText())\n",
    "    print(rulesGenerator.getRuleText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-13 17:31:02,962 - DEBUG: Processing all titles.\n",
      "2019-10-13 17:31:02,967 - DEBUG: File - /notebooks/data/Titles/title.txt\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "datasetPath =  os.path.abspath(os.path.join(dataPath, \"Titles/title.txt\"))\n",
    "\n",
    "import text_generator.title as title\n",
    "\n",
    "titleProcessor = title.Title(logging.DEBUG)\n",
    "titleProcessor.train(datasetPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'pure_word': 'be', 'stemmed_word': 'be', 'type': 'VB', 'count': 9, 'index': 2, 'positions': [2, 66, 117, 180, 192, 220, 237, 266, 312], 'proper_noun': 0, 'score': 1260.5, 'theta': 3.2142857142857144}, {'pure_word': 'Channel', 'stemmed_word': 'channel', 'type': 'NNP', 'count': 5, 'index': 10, 'positions': [10, 57, 166, 174, 294], 'proper_noun': 5, 'score': 792.0, 'theta': 16.071428571428573}, {'pure_word': 'no-deal', 'stemmed_word': 'no-deal', 'type': 'JJ', 'count': 6, 'index': 21, 'positions': [21, 50, 139, 281, 347, 424], 'proper_noun': 0, 'score': 740.0, 'theta': 33.75}, {'pure_word': 'Lorries', 'stemmed_word': 'lorri', 'type': 'NNS', 'count': 5, 'index': 0, 'positions': [0, 131, 160, 270, 386], 'proper_noun': 0, 'score': 669.0, 'theta': 0}, {'pure_word': 'Brexit', 'stemmed_word': 'brexit', 'type': 'NNP', 'count': 6, 'index': 22, 'positions': [22, 105, 140, 348, 425, 451], 'proper_noun': 5, 'score': 625.5, 'theta': 35.357142857142854}, {'pure_word': 'UK', 'stemmed_word': 'uk', 'type': 'NNP', 'count': 5, 'index': 63, 'positions': [78, 187, 232, 259, 292], 'proper_noun': 5, 'score': 618.5, 'theta': 101.25000000000004}, {'pure_word': 'simplified', 'stemmed_word': 'simplifi', 'type': 'JJ', 'count': 3, 'index': 35, 'positions': [37, 75, 153], 'proper_noun': 0, 'score': 553.0, 'theta': 56.24999999999996}, {'pure_word': 'importers', 'stemmed_word': 'import', 'type': 'NNS', 'count': 3, 'index': 29, 'positions': [30, 146, 198], 'proper_noun': 0, 'score': 498.5, 'theta': 46.60714285714283}, {'pure_word': 'firms', 'stemmed_word': 'firm', 'type': 'NNS', 'count': 4, 'index': 32, 'positions': [34, 62, 339, 437], 'proper_noun': 0, 'score': 478.0, 'theta': 51.428571428571395}, {'pure_word': 'customs', 'stemmed_word': 'custom', 'type': 'NNS', 'count': 3, 'index': 15, 'positions': [15, 151, 262], 'proper_noun': 0, 'score': 471.5, 'theta': 24.10714285714286}]\n",
      "['be', 'Channel', 'no-deal', 'Lorries', 'Brexit', 'UK', 'simplified', 'importers', 'firms', 'customs']\n",
      "['VB', 'NNP', 'JJ', 'NNS', 'NNP', 'NNP', 'JJ', 'NNS', 'NNS', 'NNS']\n",
      "{'#BEGIN#': [['Lorries', 'will'], ['New', 'guidance'], ['Hauliers', 'have'], ['The', 'industry'], ['The', 'UK'], ['Theresa', 'May'], ['Media', 'captionUp'], ['The', 'truck'], ['The', 'importer'], ['The', 'temporary'], ['The', 'latest'], ['Charlie', 'Elphicke,'], ['He', 'said'], ['However,', 'Rod'], ['Business', 'is'], ['The', 'systems'], ['It', 'emerged']], ('Lorries', 'will'): ['be'], ('will', 'be'): ['able'], ('be', 'able'): ['to', 'to'], ('able', 'to'): ['drive', 'drive'], ('to', 'drive'): ['straight', 'straight'], ('drive', 'straight'): ['off', 'into'], ('straight', 'off'): ['ferries'], ('off', 'ferries'): ['and'], ('ferries', 'and'): ['Channel'], ('and', 'Channel'): ['Tunnel'], ('Channel', 'Tunnel'): ['trains'], ('Tunnel', 'trains'): ['without'], ('trains', 'without'): ['making'], ('without', 'making'): ['customs'], ('making', 'customs'): ['declarations'], ('customs', 'declarations'): ['in'], ('declarations', 'in'): ['the'], ('in', 'the'): ['event', 'event', 'day', 'event'], ('the', 'event'): ['of', 'of', 'of'], ('event', 'of'): ['a', 'no-deal.', 'a'], ('of', 'a'): ['no-deal', 'no-deal', 'no-deal'], ('a', 'no-deal'): ['Brexit,', 'Brexit', 'Brexit.'], ('no-deal', 'Brexit,'): ['the', 'he'], ('Brexit,', 'the'): ['government'], ('the', 'government'): ['has', 'plans'], ('government', 'has'): ['announced.'], ('New', 'guidance'): ['for'], ('guidance', 'for'): ['importers'], ('for', 'importers'): ['and'], ('importers', 'and'): ['hauliers'], ('and', 'hauliers'): ['says'], ('hauliers', 'says'): ['firms'], ('says', 'firms'): ['would'], ('firms', 'would'): ['file', 'still'], ('would', 'file'): ['a'], ('file', 'a'): ['simplified', 'very'], ('a', 'simplified'): ['form', 'frontier'], ('simplified', 'form'): ['online'], ('form', 'online'): ['in'], ('online', 'in'): ['advance'], ('in', 'advance'): ['and'], ('advance', 'and'): ['pay'], ('and', 'pay'): ['duty'], ('pay', 'duty'): ['later.'], ('Hauliers', 'have'): ['warned'], ('have', 'warned'): ['that'], ('warned', 'that'): ['no-deal'], ('that', 'no-deal'): ['could'], ('no-deal', 'could'): ['result'], ('could', 'result'): ['in'], ('result', 'in'): ['long'], ('in', 'long'): ['queues'], ('long', 'queues'): ['at'], ('queues', 'at'): ['Channel'], ('at', 'Channel'): ['ports.'], ('The', 'industry'): ['said'], ('industry', 'said'): ['firms'], ('said', 'firms'): ['would'], ('would', 'still'): ['not'], ('still', 'not'): ['be'], ('not', 'be'): ['ready'], ('be', 'ready'): ['for'], ('ready', 'for'): ['a', 'a'], ('for', 'a'): ['chaotic', 'chaotic'], ('a', 'chaotic'): ['EU', 'no-deal'], ('chaotic', 'EU'): ['exit'], ('EU', 'exit'): ['-'], ('exit', '-'): ['even'], ('-', 'even'): ['with'], ('even', 'with'): ['these'], ('with', 'these'): ['simplified'], ('these', 'simplified'): ['procedures.'], ('The', 'UK'): ['is'], ('UK', 'is'): ['due'], ('is', 'due'): ['to', 'to'], ('due', 'to'): ['leave', 'cross'], ('to', 'leave'): ['the'], ('leave', 'the'): ['EU'], ('the', 'EU'): ['at'], ('EU', 'at'): ['23:00'], ('at', '23:00'): ['GMT'], ('23:00', 'GMT'): ['on'], ('GMT', 'on'): ['Friday'], ('on', 'Friday'): ['29'], ('Friday', '29'): ['March'], ('29', 'March'): ['-'], ('March', '-'): ['with'], ('-', 'with'): ['or'], ('with', 'or'): ['without'], ('or', 'without'): ['a'], ('without', 'a'): ['deal.'], ('Theresa', 'May'): ['has'], ('May', 'has'): ['said'], ('has', 'said'): ['she'], ('said', 'she'): ['is'], ('she', 'is'): ['determined'], ('is', 'determined'): ['to'], ('determined', 'to'): ['deliver'], ('to', 'deliver'): ['Brexit'], ('deliver', 'Brexit'): ['on'], ('Brexit', 'on'): ['time,', 'its'], ('on', 'time,'): ['but'], ('time,', 'but'): ['a'], ('but', 'a'): ['number'], ('a', 'number'): ['of'], ('number', 'of'): ['cabinet'], ('of', 'cabinet'): ['ministers'], ('cabinet', 'ministers'): ['have'], ('ministers', 'have'): ['indicated'], ('have', 'indicated'): ['they'], ('indicated', 'they'): ['would'], ('they', 'would'): ['be'], ('would', 'be'): ['willing', 'payable', 'reviewed'], ('be', 'willing'): ['to'], ('willing', 'to'): ['agree'], ('to', 'agree'): ['to'], ('agree', 'to'): ['a'], ('to', 'a'): ['short'], ('a', 'short'): ['extension'], ('short', 'extension'): ['to'], ('extension', 'to'): ['finalise'], ('to', 'finalise'): ['legislation.'], ('Media', 'captionUp'): ['to'], ('captionUp', 'to'): ['90'], ('to', '90'): ['lorries'], ('90', 'lorries'): ['assembled'], ('lorries', 'assembled'): ['at'], ('assembled', 'at'): ['Manston'], ('at', 'Manston'): ['airfield'], ('Manston', 'airfield'): ['as'], ('airfield', 'as'): ['part'], ('as', 'part'): ['of', 'of'], ('part', 'of'): ['a', 'an'], ('no-deal', 'Brexit'): ['exercise'], ('Brexit', 'exercise'): ['These'], ('exercise', 'These'): ['would'], ('These', 'would'): ['allow'], ('would', 'allow'): ['an'], ('allow', 'an'): ['importer'], ('an', 'importer'): ['to'], ('importer', 'to'): ['file'], ('to', 'file'): ['a'], ('a', 'very'): ['short'], ('very', 'short'): ['customs'], ('short', 'customs'): ['form'], ('customs', 'form'): ['-'], ('form', '-'): ['a'], ('-', 'a'): ['simplified'], ('simplified', 'frontier'): ['declaration\"'], ('frontier', 'declaration\"'): ['-'], ('declaration\"', '-'): ['only'], ('-', 'only'): ['two'], ('only', 'two'): ['hours'], ('two', 'hours'): ['before'], ('hours', 'before'): ['a'], ('before', 'a'): ['lorry'], ('a', 'lorry'): ['is'], ('lorry', 'is'): ['due'], ('to', 'cross'): ['the'], ('cross', 'the'): ['Channel'], ('the', 'Channel'): ['by', 'Tunnel.'], ('Channel', 'by'): ['ferry,'], ('by', 'ferry,'): ['or'], ('ferry,', 'or'): ['one'], ('or', 'one'): ['hour'], ('one', 'hour'): ['via'], ('hour', 'via'): ['the'], ('via', 'the'): ['Channel'], ('The', 'truck'): ['would'], ('truck', 'would'): ['then'], ('would', 'then'): ['be'], ('then', 'be'): ['able'], ('straight', 'into'): ['the'], ('into', 'the'): ['UK'], ('the', 'UK'): ['without'], ('UK', 'without'): ['any'], ('without', 'any'): ['further'], ('any', 'further'): ['paperwork'], ('further', 'paperwork'): ['being'], ('paperwork', 'being'): ['done'], ('being', 'done'): ['at'], ('done', 'at'): ['the'], ('at', 'the'): ['border.'], ('The', 'importer'): ['would'], ('importer', 'would'): ['have'], ('would', 'have'): ['to'], ('have', 'to'): ['update'], ('to', 'update'): ['the'], ('update', 'the'): ['computer'], ('the', 'computer'): ['entry'], ('computer', 'entry'): ['within'], ('entry', 'within'): ['24'], ('within', '24'): ['hours'], ('24', 'hours'): ['to'], ('hours', 'to'): ['tell'], ('to', 'tell'): ['HMRC'], ('tell', 'HMRC'): ['the'], ('HMRC', 'the'): ['goods'], ('the', 'goods'): ['had'], ('goods', 'had'): ['arrived,'], ('had', 'arrived,'): ['and'], ('arrived,', 'and'): ['the'], ('and', 'the'): ['duty'], ('the', 'duty'): ['would'], ('duty', 'would'): ['be'], ('be', 'payable'): ['as'], ('payable', 'as'): ['much'], ('as', 'much'): ['as'], ('much', 'as'): ['a'], ('as', 'a'): ['month', '\"common'], ('a', 'month'): ['after'], ('month', 'after'): ['the'], ('after', 'the'): ['shipment'], ('the', 'shipment'): ['had'], ('shipment', 'had'): ['entered'], ('had', 'entered'): ['the'], ('entered', 'the'): ['UK.'], ('The', 'temporary'): ['system'], ('temporary', 'system'): ['would'], ('system', 'would'): ['be'], ('be', 'reviewed'): ['after'], ('reviewed', 'after'): ['three'], ('after', 'three'): ['months,'], ('three', 'months,'): ['but'], ('months,', 'but'): ['is'], ('but', 'is'): ['expected'], ('is', 'expected'): ['to'], ('expected', 'to'): ['last'], ('to', 'last'): ['more'], ('last', 'more'): ['than'], ('more', 'than'): ['a'], ('than', 'a'): ['year.'], ('The', 'latest'): ['guidance'], ('latest', 'guidance'): ['applies'], ('guidance', 'applies'): ['only'], ('applies', 'only'): ['to'], ('only', 'to'): ['vehicles'], ('to', 'vehicles'): ['entering'], ('vehicles', 'entering'): ['the'], ('entering', 'the'): ['UK,'], ('the', 'UK,'): ['but'], ('UK,', 'but'): ['additional'], ('but', 'additional'): ['customs'], ('additional', 'customs'): ['checks'], ('customs', 'checks'): ['may'], ('checks', 'may'): ['also'], ('may', 'also'): ['be'], ('also', 'be'): ['introduced'], ('be', 'introduced'): ['for'], ('introduced', 'for'): ['EU-bound'], ('for', 'EU-bound'): ['lorries'], ('EU-bound', 'lorries'): ['arriving'], ('lorries', 'arriving'): ['at'], ('arriving', 'at'): ['Calais,'], ('at', 'Calais,'): ['Coquelles'], ('Calais,', 'Coquelles'): ['and'], ('Coquelles', 'and'): ['Dunkirk'], ('and', 'Dunkirk'): ['in'], ('Dunkirk', 'in'): ['the'], ('Charlie', 'Elphicke,'): ['the'], ('Elphicke,', 'the'): ['Conservative'], ('the', 'Conservative'): ['MP'], ('Conservative', 'MP'): ['for'], ('MP', 'for'): ['Dover'], ('for', 'Dover'): ['-'], ('Dover', '-'): ['home'], ('-', 'home'): ['to'], ('home', 'to'): ['the'], ('to', 'the'): [\"UK's\", 'Port'], ('the', \"UK's\"): ['busiest'], (\"UK's\", 'busiest'): ['Channel'], ('busiest', 'Channel'): ['port'], ('Channel', 'port'): ['-'], ('port', '-'): ['described'], ('-', 'described'): ['the'], ('described', 'the'): ['plans'], ('the', 'plans'): ['as'], ('plans', 'as'): ['a'], ('a', '\"common'): ['sense'], ('\"common', 'sense'): ['move\".'], ('He', 'said'): ['he'], ('said', 'he'): ['had'], ('he', 'had'): ['long'], ('had', 'long'): ['argued'], ('long', 'argued'): ['that'], ('argued', 'that'): ['checks'], ('that', 'checks'): ['can'], ('checks', 'can'): ['be'], ('can', 'be'): ['done'], ('be', 'done'): ['away'], ('done', 'away'): ['from'], ('away', 'from'): ['the'], ('from', 'the'): ['border', 'Road', 'disused'], ('the', 'border'): ['-'], ('border', '-'): ['so'], ('-', 'so'): ['traffic'], ('so', 'traffic'): ['can'], ('traffic', 'can'): ['keep'], ('can', 'keep'): ['flowing'], ('keep', 'flowing'): ['smoothly.'], ('However,', 'Rod'): ['McKenzie,'], ('Rod', 'McKenzie,'): ['from'], ('McKenzie,', 'from'): ['the'], ('the', 'Road'): ['Haulage'], ('Road', 'Haulage'): ['Association,'], ('Haulage', 'Association,'): ['said'], ('Association,', 'said'): ['the'], ('said', 'the'): ['guidance'], ('the', 'guidance'): ['would'], ('guidance', 'would'): ['not'], ('would', 'not'): ['help'], ('not', 'help'): ['trucking'], ('help', 'trucking'): ['firms.'], ('Business', 'is'): ['simply'], ('is', 'simply'): ['not'], ('simply', 'not'): ['ready'], ('not', 'ready'): ['for'], ('chaotic', 'no-deal'): ['Brexit,'], ('Brexit,', 'he'): ['said.'], ('The', 'systems'): [\"aren't\"], ('systems', \"aren't\"): ['in'], (\"aren't\", 'in'): ['place,'], ('in', 'place,'): ['the'], ('place,', 'the'): ['staff'], ('the', 'staff'): ['are'], ('staff', 'are'): ['not'], ('are', 'not'): ['trained,'], ('not', 'trained,'): ['there'], ('trained,', 'there'): [\"isn't\"], ('there', \"isn't\"): ['the'], (\"isn't\", 'the'): ['time'], ('the', 'time'): ['in'], ('time', 'in'): ['the'], ('the', 'day'): ['for'], ('day', 'for'): ['hauliers'], ('for', 'hauliers'): ['and'], ('hauliers', 'and'): ['businesses'], ('and', 'businesses'): ['to'], ('businesses', 'to'): ['do'], ('to', 'do'): ['all'], ('do', 'all'): ['the'], ('all', 'the'): ['paperwork,'], ('the', 'paperwork,'): ['he'], ('paperwork,', 'he'): ['told'], ('he', 'told'): ['the'], ('told', 'the'): ['BBC'], ('the', 'BBC'): ['Last'], ('BBC', 'Last'): ['month,'], ('Last', 'month,'): ['a'], ('month,', 'a'): ['convoy'], ('a', 'convoy'): ['of'], ('convoy', 'of'): ['89'], ('of', '89'): ['lorries'], ('89', 'lorries'): ['took'], ('lorries', 'took'): ['part'], ('took', 'part'): ['in'], ('part', 'in'): ['two'], ('in', 'two'): ['runs'], ('two', 'runs'): ['from'], ('runs', 'from'): ['the'], ('the', 'disused'): ['Manston'], ('disused', 'Manston'): ['Airport,'], ('Manston', 'Airport,'): ['near'], ('Airport,', 'near'): ['Ramsgate'], ('near', 'Ramsgate'): ['in'], ('Ramsgate', 'in'): ['Kent,'], ('in', 'Kent,'): ['on'], ('Kent,', 'on'): ['a'], ('on', 'a'): ['20-mile'], ('a', '20-mile'): ['route'], ('20-mile', 'route'): ['to'], ('route', 'to'): ['the'], ('the', 'Port'): ['of'], ('Port', 'of'): ['Dover'], ('of', 'Dover'): ['as'], ('Dover', 'as'): ['part'], ('of', 'an'): ['exercise'], ('an', 'exercise'): ['to'], ('exercise', 'to'): ['test'], ('to', 'test'): ['plans'], ('test', 'plans'): ['for'], ('plans', 'for'): ['border'], ('for', 'border'): ['disruption'], ('border', 'disruption'): ['in'], ('disruption', 'in'): ['the'], ('It', 'emerged'): ['on'], ('emerged', 'on'): ['Tuesday'], ('on', 'Tuesday'): ['that'], ('Tuesday', 'that'): ['the'], ('that', 'the'): ['government'], ('government', 'plans'): ['to'], ('plans', 'to'): ['pay'], ('to', 'pay'): ['a'], ('pay', 'a'): ['law'], ('a', 'law'): ['firm'], ('law', 'firm'): ['£800,000'], ('firm', '£800,000'): ['for'], ('£800,000', 'for'): ['advice'], ('for', 'advice'): ['in'], ('advice', 'in'): ['case'], ('in', 'case'): ['Eurotunnel'], ('case', 'Eurotunnel'): ['decides'], ('Eurotunnel', 'decides'): ['to'], ('decides', 'to'): ['sue'], ('to', 'sue'): ['over'], ('sue', 'over'): ['the'], ('over', 'the'): ['effects'], ('the', 'effects'): ['of'], ('effects', 'of'): ['Brexit'], ('of', 'Brexit'): ['on'], ('on', 'its'): ['business.']}\n",
      "---------- be --------\n",
      "---------- channel --------\n",
      "['ports']\n",
      "---------- no-deal --------\n",
      "['brexit', 'offer']\n",
      "---------- lorries --------\n",
      "---------- brexit --------\n",
      "['deal', 'warning', 'disruption']\n",
      "---------- uk --------\n",
      "['plans', 'businesses', 'government', 'drivers']\n",
      "---------- simplified --------\n",
      "---------- importers --------\n",
      "---------- firms --------\n",
      "---------- customs --------\n"
     ]
    }
   ],
   "source": [
    "#Brexit: Customs checks to be simplified in no-deal situation.\n",
    "textbrexit = \"\"\"\n",
    "Lorries will be able to drive straight off ferries and Channel Tunnel trains without making customs declarations in the event of a no-deal Brexit, the government has announced.\n",
    "New guidance for importers and hauliers says firms would file a simplified form online in advance and pay duty later.\n",
    "Hauliers have warned that no-deal could result in long queues at Channel ports.\n",
    "The industry said firms would still not be ready for a chaotic EU exit - even with these simplified procedures.\n",
    "The UK is due to leave the EU at 23:00 GMT on Friday 29 March - with or without a deal.\n",
    "Theresa May has said she is determined to deliver Brexit on time, but a number of cabinet ministers have indicated they would be willing to agree to a short extension to finalise legislation.\n",
    "Media captionUp to 90 lorries assembled at Manston airfield as part of a no-deal Brexit exercise\n",
    "These would allow an importer to file a very short customs form - a simplified frontier declaration\" - only two hours before a lorry is due to cross the Channel by ferry, or one hour via the Channel Tunnel.\n",
    "The truck would then be able to drive straight into the UK without any further paperwork being done at the border.\n",
    "The importer would have to update the computer entry within 24 hours to tell HMRC the goods had arrived, and the duty would be payable as much as a month after the shipment had entered the UK.\n",
    "The temporary system would be reviewed after three months, but is expected to last more than a year.\n",
    "The latest guidance applies only to vehicles entering the UK, but additional customs checks may also be introduced for EU-bound lorries arriving at Calais, Coquelles and Dunkirk in the event of no-deal.\n",
    "Charlie Elphicke, the Conservative MP for Dover - home to the UK's busiest Channel port - described the plans as a \"common sense move\".\n",
    "He said he had long argued that checks can be done away from the border - so traffic can keep flowing smoothly.\n",
    "However, Rod McKenzie, from the Road Haulage Association, said the guidance would not help trucking firms.\n",
    "Business is simply not ready for a chaotic no-deal Brexit, he said.\n",
    "The systems aren't in place, the staff are not trained, there isn't the time in the day for hauliers and businesses to do all the paperwork, he told the BBC\n",
    "Last month, a convoy of 89 lorries took part in two runs from the disused Manston Airport, near Ramsgate in Kent, on a 20-mile route to the Port of Dover as part of an exercise to test plans for border disruption in the event of a no-deal Brexit.\n",
    "It emerged on Tuesday that the government plans to pay a law firm £800,000 for advice in case Eurotunnel decides to sue over the effects of Brexit on its business.\n",
    "\"\"\"\n",
    "\n",
    "textii = \"\"\"\n",
    "\n",
    "Lorries will be able to drive straight off ferries and Channel Tunnel trains without making customs declarations in the event of a no-deal Brexit, the government has announced.\n",
    "New guidance for importers and hauliers says firms would file a simplified form online in advance and pay duty later.\n",
    "Hauliers have warned that no-deal could result in long queues at Channel ports.\n",
    "The industry said firms would still not be ready for a chaotic EU exit - even with these simplified procedures.\n",
    "The UK is due to leave the EU at 23:00 GMT on Friday 29 March - with or without a deal.\n",
    "Theresa May has said she is determined to deliver Brexit on time, but a number of cabinet ministers have indicated they would be willing to agree to a short extension to finalise legislation.\n",
    "Media captionUp to 90 lorries assembled at Manston airfield as part of a no-deal Brexit exercise\n",
    "These would allow an importer to file a very short customs form - a simplified frontier declaration\" - only two hours before a lorry is due to cross the Channel by ferry, or one hour via the Channel Tunnel.\n",
    "The truck would then be able to drive straight into the UK without any further paperwork being done at the border.\n",
    "The importer would have to update the computer entry within 24 hours to tell HMRC the goods had arrived, and the duty would be payable as much as a month after the shipment had entered the UK.\n",
    "The temporary system would be reviewed after three months, but is expected to last more than a year.\n",
    "The latest guidance applies only to vehicles entering the UK, but additional customs checks may also be introduced for EU-bound lorries arriving at Calais, Coquelles and Dunkirk in the event of no-deal.\n",
    "Charlie Elphicke, the Conservative MP for Dover - home to the UK's busiest Channel port - described the plans as a \"common sense move\".\n",
    "He said he \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "titleProcessor.getTitle(textbrexit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Customs', 'NNS'), ('checks', 'NNS'), ('to', 'TO'), ('be', 'VB'), ('simplified', 'VBN'), ('in', 'IN'), ('no-deal', 'JJ'), ('situation', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "tokens = word_tokenize(\"Customs checks to be simplified in no-deal situation.\")\n",
    "tags = pos_tag(tokens)\n",
    "print(tags)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brexit to be Brexit\n",
      "Brexit to be Channel\n",
      "Brexit to be importers\n",
      "Brexit to be firms\n",
      "Brexit to be customs\n",
      "Brexit to be lorries\n",
      "Channel to be Brexit\n",
      "Channel to be Channel\n",
      "Channel to be importers\n",
      "Channel to be firms\n",
      "Channel to be customs\n",
      "Channel to be lorries\n",
      "importers to be Brexit\n",
      "importers to be Channel\n",
      "importers to be importers\n",
      "importers to be firms\n",
      "importers to be customs\n",
      "importers to be lorries\n",
      "firms to be Brexit\n",
      "firms to be Channel\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP NP\n",
    "NP -> NNP | NNPS | NN | NNS\n",
    "VP -> TO VB \n",
    "NPE -> JJ NNP | JJ NNPS | JJ NN | JJ NNS\n",
    "DT -> \"the\"|\"these\"\n",
    "TO -> \"to\"\n",
    "MD -> \"would\" | \"will\"\n",
    "VB -> \"be\"\n",
    "IN -> \"in\" | \"at\"\n",
    "CC -> \"and\" | \"but\"\n",
    "NNP -> \"Brexit\" | \"Channel\"\n",
    "JJ -> \"no-deal\" | \"simplified\"\n",
    "NNS -> \"importers\" | \"firms\" | \"customs\" | \"lorries\"\n",
    "VBZ -> \"is\" | \"has\"\n",
    "VBD -> \"said\" | \"had\"\n",
    "VBP -> \"have\" | \"are\" \n",
    "RB -> \"straight\" | \"not\"\n",
    "PRP -> \"He\" | \"she\"\n",
    "VBG -> \"making\" | \"flowing\"\n",
    "VBN -> \"announced\" | \"arrived\"\n",
    "JJR -> \"more\" \n",
    "JJS -> \"latest\" | \"busiest\"\n",
    "EX -> \"there\" \n",
    "PDT -> \"all\"\n",
    "\"\"\")\n",
    "\n",
    "for sentence in generate(grammar, n=20):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
